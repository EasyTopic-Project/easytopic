# flexsegmentation :man_teacher:

## Description
``flexsegmentation`` is a versatile architecture for automatically performing topic segmentation on video lectures. 

Video lectures are very popular nowadays. Following the new teaching trends, people are increasingly seeking educational videos on the web
for the most different purposes: learn something new, review content for exams or just out of curiosity. Unfortunately, finding specific
content in this type of video is not an easy task. Many video lectures are extensive and cover several topics, and not all of these topics
are relevant to the user who has found the video. The result is that the user spends so much time trying to find topic of interest in the
middle of content irrelevant to him. The temporal segmentation of video lectures in topics can solve this problem allowing users to
navigate of a non-linear way through all topics of a video lecture. However, temporal video lecture segmentation is not an easy task
and needs to be automatized.


And that's where ``flexsegmentation`` comes in. The architecture provides the entire processing pipeline from feature extraction to
timestamp topic detection. The use of only extracted audio features automatically makes it a versatile approach that can be employed in
a large universe of video lectures, as it does not depend on the availability of other sources such as slide shows, textbooks, 
or subtitle manually generated.

This architecture is derived from my master's thesis and you can check the [Publications section](#publications) for aditional information.


## Publications
